---
title: "Krystalografia"
author: "Joanna So³omiewicz"
date: "15 listopada 2018"
output: 
  html_document: 
    theme: spacelab
    toc: yes
    toc_float: yes
---
#Podsumowanie analizy danych
W mojej analizie na samym pocz¹tku przy wczytywaniu danych odrzuci³am atrybuty, które nie s¹ przeze mnie u¿ywane w dalszej analizie, ani regresji b¹dŸ klasyfikacji.

Nastêpnie z mojego zbioru usunê³am rekordy, w których wyst¹pi³a niewiadoma wartoœæ. Zdecydowa³am siê na usuniêcie, poniewa¿ zbiór danych jest na tyle du¿y, ¿e mog³am sobie na to pozwoliæ zamiast zastêpowania tych wartoœci œrednimi, co jest pewnego rodzaju przek³amaniem.

Dodatkowo ze zbioru pozby³am siê tych ligandów, które zosta³y uwzglêdnione w zbiorze do usuniêcia.

W kolejnym punkcie wykona³am krótkie podsumowanie najwa¿niejszych danych wykorzystywanych w dalszym przetwarzaniu.

Nastêpnie znalaz³am 50 najczêœciej wystêpuj¹cych ligandów i ograniczy³am zbiór w³aœnie do nich oraz przedstawi³am je na histogramie, posortowane wed³ug czêstoœci wyst¹pienia.

Jednym z wyzwañ by³o przedstawienie korelacji miêdzy zmiennymi. Chcia³am w tym celu u¿yæ biblioteki corrplot, która przedstawia graficznie macierz korelacji. Niestety przy tak du¿ej iloœci atrybutów musia³am z tego zrezygnowaæ i postanowi³am przedstawiæ korelacje w postaci tabeli dodatkowo ograniczaj¹c wyniki tylko do tych, gdzie korelacja jest wiêksza b¹dŸ równa **0.999**.

Aby zaprezentowaæ rozk³ad wartoœci liczby atomów i elektronów zastosowa³am wykresy gêstoœciowe.

Dziesiêæ najwiêkszych niezgodnoœci liczby atomów i elektronów przedstawi³am w formie tabeli, podaj¹c dla ka¿dej grupy ligandów uœrednion¹ ró¿nicê.

Kolejnym z wyzwañ by³o zaprezentowanie rozk³adu wartoœci kolumn part_01. Wynika³o to z iloœci tych kolumn. W celu drobnej optymalizacji czytelnoœci wykresów zastosowa³am krok usuniêcia outlier'ów oraz odciêcia prefixu "part_01_" z nazw kolumn, poniewa¿ wystêpowa³ w ka¿dej z nich. Pocz¹tkowo planowa³am zastosowaæ bibliotekê ggplot2, niestety nie dawa³a rady nawet przy 10 tysi¹cach rekordów. Nastêpnie ca³oœæ przepisa³am na bibliotekê plotly, co zadzia³a³o dla 10 tysiêcy rekordów, ale niestety dla ca³oœci danych wygenerowa³o raport wielkoœci ponad 0.4 GB, którego nie by³am w stanie otworzyæ w przegl¹darce. Ostatecznie by³am zmuszona u¿yæ najprostszego rozwi¹zania ze statycznymi wykresami.

Regresjê liniow¹ wykona³am dla standardowych parametrów. Stratyfikowany podzia³ zbioru na ucz¹cy i testowy jako odpowiednio **70%** i **30%** danych oraz wykorzystanie funkcji **lm**.

Tworz¹c klasyfikator zmieni³am stosunek podzia³u na zbiór ucz¹cy i testowy, poniewa¿ danych by³o wystarczaj¹co du¿o. Dlatego ostatecznie stratyfikowany podzia³ wynosi **99%** danych dla zbioru ucz¹cego i **1%** dla zbioru testowego. Do uczenia u¿y³am algorytmu **Random Forest** z parametrem **ntrees = 1000**.

#Wykorzystane biblioteki
```{r loading libraries, message = FALSE}
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyr)
library(knitr)
library(caret)
library(data.table)
library(tibble)
```

#Wczytywanie danych
```{r reading data}
removable_columns <- c("title", "pdb_code", "res_id", "chain_id", "local_res_atom_count", "local_res_atom_non_h_occupancy_sum", "local_res_atom_non_h_electron_occupancy_sum", "local_res_atom_C_count", "local_res_atom_N_count", "local_res_atom_O_count", "local_res_atom_S_count", "dict_atom_C_count", "dict_atom_N_count", "dict_atom_O_count", "dict_atom_S_count", "skeleton_data", "skeleton_cycle_4", "skeleton_diameter", "skeleton_cycle_6", "skeleton_cycle_7", "skeleton_closeness_006_008", "skeleton_closeness_002_004", "skeleton_cycle_3", "skeleton_avg_degree", "skeleton_closeness_004_006", "skeleton_closeness_010_012", "skeleton_closeness_012_014", "skeleton_edges", "skeleton_radius", "skeleton_cycle_8_plus", "skeleton_closeness_020_030", "skeleton_deg_5_plus", "skeleton_closeness_016_018", "skeleton_closeness_008_010", "skeleton_closeness_018_020", "skeleton_average_clustering", "skeleton_closeness_040_050", "skeleton_closeness_014_016", "skeleton_center", "skeleton_closeness_000_002", "skeleton_density", "skeleton_closeness_030_040", "skeleton_deg_4", "skeleton_deg_0", "skeleton_deg_1", "skeleton_deg_2", "skeleton_deg_3", "skeleton_graph_clique_number", "skeleton_nodes", "skeleton_cycles", "skeleton_cycle_5", "skeleton_closeness_050_plus", "skeleton_periphery", "fo_col", "fc_col", "weight_col", "grid_space", "solvent_radius", "solvent_opening_radius", "part_step_FoFc_std_min", "part_step_FoFc_std_max", "part_step_FoFc_std_step")

data <- fread("./all_summary.csv", nrows = 10000, header = TRUE, drop = removable_columns)
```

#Przetwarzanie brakuj¹cych danych
```{r processing missing data}
data <- data %>% 
  drop_na()
```

#Usuwanie niepotrzebnych ligandów
```{r deleting chosen ligands}
deletable_res_name <- c("UNK", "UNX", "UNL", "DUM", "N", "BLOB", "ALA", "ARG", "ASN", "ASP", "CYS", "GLN", "GLU", "GLY", "HIS", "ILE", "LEU", "LYS", "MET", "MSE", "PHE", "PRO", "SEC", "SER", "THR", "TRP", "TYR", "VAL", "DA", "DG", "DT", "DC", "DU", "A", "G", "T", "C", "U", "HOH", "H20", "WAT")
data <- data %>% filter(!res_name %in% deletable_res_name)
```

#Podsumowanie danych
```{r data summary}
cols_summary <- c("res_name", "local_res_atom_non_h_count", "local_res_atom_non_h_electron_sum", "dict_atom_non_h_count", "dict_atom_non_h_electron_sum")
statistics <- data %>%
  select(one_of(cols_summary))
kable(summary(statistics))
dim(data)
```

#50 najpopularniejszych ligandów
```{r 50 most popular ligands}
popular_ligands <- data %>%
  select(res_name) %>%
  count(res_name, sort = TRUE) %>%
  slice(1:50)

popular_names_vector <- popular_ligands %>%
  pull(res_name)

data <- data %>% filter(res_name %in% popular_names_vector)
```

#Korelacja miêdzy zmiennymi
```{r correlation between variables, warning=FALSE}
data %>%
  select_if(is.numeric) %>%
  cor() %>%
  as.data.frame() %>%
  rownames_to_column() %>%
  gather(rowname2, value, -rowname) %>%
  filter(value >= 0.9999, rowname != rowname2) %>%
  kable()
```

#Licznoœæ najpopularniejszych ligandów wed³ug nazwy
```{r cardinality of ligands}
plot_ligands <- ggplot(popular_ligands, aes(x = reorder(res_name, -n), y = n, fill = n)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90)) +
  xlab("ligand")+
  ylab("licznoœæ") +
  labs(title = "Licznoœæ ligandów wed³ug nazwy")

ggplotly(plot_ligands)
```

#Rozk³ady gêstoœciowe liczb
##Atomów
```{r distribution of atom count}
plot_atom <- ggplot(data, aes(x = local_res_atom_non_h_count)) +
  geom_density(alpha = .3, fill = "#00CECB", color = NA) +
  xlab("licznoœæ atomów") +
  ylab("gêstoœæ") +
  labs(title = "Rozk³ad gêstoœciowy atomów")

ggplotly(plot_atom)
```

##Elektronów
```{r distribution of electron count}
plot_electron <- ggplot(data, aes(x = local_res_atom_non_h_electron_sum)) +
  geom_density(alpha = .3, fill = "#FF5E5B", color = NA) +
  xlab("licznoœæ elektronów") +
  ylab("gêstoœæ") +
  labs(title = "Rozk³ad gêstoœciowy elektronów")

ggplotly(plot_electron)
```

#Najwiêksze niezgodnoœci liczby
##Atomów
```{r greatest inconsistency in atom}
data %>%
  select(res_name, local_res_atom_non_h_count, dict_atom_non_h_count) %>%
  group_by(res_name) %>%
  summarise(atom_inconsistency = mean(abs(local_res_atom_non_h_count - dict_atom_non_h_count))) %>%
  arrange(-atom_inconsistency) %>%
  slice(1:10) %>%
  kable()
```

##Elektronów
```{r greatest inconsistency in electron}
data %>%
  select(res_name, local_res_atom_non_h_electron_sum, dict_atom_non_h_electron_sum) %>%
  group_by(res_name) %>%
  summarise(electron_inconsistency = mean(abs(local_res_atom_non_h_electron_sum - dict_atom_non_h_electron_sum))) %>%
  arrange(-electron_inconsistency) %>%
  slice(1:10) %>%
  kable()
```

#Rozk³ad wartoœci kolumn part_01
```{r distribution of part_01 columns, fig.height = 50, fig.width = 15}
remove_outliers <- function(data, na.rm = TRUE, ...) {
  qnt <- quantile(data, probs=c(.25, .75), na.rm = na.rm, ...)
  iqr <- 1.5 * IQR(data, na.rm = na.rm)
  data_no_outliers <- data
  data_no_outliers[data < (qnt[1] - iqr)] <- NA
  data_no_outliers[data > (qnt[2] + iqr)] <- NA
  data_no_outliers[!is.na(data_no_outliers)]
  data_no_outliers
}

plot_part_data <- data %>%
  select(contains("part_01"))

plot_part_data <- plot_part_data %>%
  sapply(remove_outliers) %>%
  as.data.frame() %>%
  drop_na()

names(plot_part_data) <- gsub("part_01_", "", names(plot_part_data))

plot_part_data <- plot_part_data %>%
  gather(part, value, 1:106)

ggplot(plot_part_data, aes(x = part, y = value)) +
  geom_boxplot() +
  facet_wrap(~part, scales = "free", ncol = 6) +
  labs(title = "Rozk³ad wartoœci kolumn part_01")
```

#Regresja liniowa
##Liczba atomów
```{r linear regression atom, error=FALSE, warning=FALSE, message=FALSE}
data_partition <- data %>%
  select_if(is.numeric)

set.seed(111)
partition <- createDataPartition(
  y = data_partition$local_res_atom_non_h_count,
  p = .7,
  list = FALSE)

data_train <- data_partition %>%
  slice(partition)
data_test <- data_partition %>%
  slice(-partition)

set.seed(111)
fit <- train(local_res_atom_non_h_count ~ ., data = data_train, method = "lm")
fit

set.seed(111)
prediction <- predict(fit, newdata = data_test)
postResample(pred = prediction, obs = data_test$local_res_atom_non_h_count)
```

##Liczba elektronów
```{r linear regression electron, error=FALSE, warning=FALSE, message=FALSE}
data_partition <- data %>%
  select_if(is.numeric)

set.seed(111)
partition <- createDataPartition(
  y = data_partition$local_res_atom_non_h_electron_sum,
  p = .7,
  list = FALSE)

data_train <- data_partition %>%
  slice(partition)
data_test <- data_partition %>%
  slice(-partition)

set.seed(111)
fit <- train(local_res_atom_non_h_electron_sum ~ ., data = data_train, method = "lm")
fit

set.seed(111)
prediction <- predict(fit, newdata = data_test)
postResample(pred = prediction, obs = data_test$local_res_atom_non_h_electron_sum)
```

#Klasyfikator
####Przewidywanie wartoœci res_name
```{r classification}
removable_columns <- c("blob_coverage", "res_coverage", "local_res_atom_non_h_count", "local_res_atom_non_h_electron_sum", "dict_atom_non_h_count", "dict_atom_non_h_electron_sum")
data_partition <- data %>%
  select(-removable_columns)

data_partition$res_name <- as.factor(data_partition$res_name)

set.seed(111)
partition <- createDataPartition(
  y = data_partition$res_name,
  p = .99,
  list = FALSE)

data_train <- data_partition %>%
  slice(partition)
data_test <- data_partition %>%
  slice(-partition)

set.seed(111)
fit <- train(
  res_name ~ .,
  data = data_train,
  method = "rf",
  ntree = 1000,
  na.action  = na.pass)
fit

set.seed(111)
prediction <- predict(fit, newdata = data_test)
confusionMatrix(data = prediction, data_test$res_name)
```

